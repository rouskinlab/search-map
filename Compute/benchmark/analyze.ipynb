{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb55640-0c5f-499f-a24d-3235c52f9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "\n",
    "from pathlib import Path\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "\n",
    "from seismicrna.cluster.compare import assign_clusterings\n",
    "from seismicrna.cluster.report import ClusterReport, NumUniqReadKeptF, NumClustsF\n",
    "from seismicrna.core.header import parse_header\n",
    "from seismicrna.core.mu import calc_pearson\n",
    "from seismicrna.mask.report import MaskReport, NumReadsKeptF\n",
    "from seismicrna.table.base import MUTAT_REL\n",
    "from seismicrna.table.load import ClustFreqTableLoader, load_pos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5ada9d-8667-49da-95f1-7cd4b4976eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure.\n",
    "\n",
    "MAX_CLUSTERS_REAL = 4\n",
    "MAX_CLUSTERS_OBS = 5\n",
    "PROP_NAMES = [\"Balanced\", \"Unbalanced\", \"Very Unbalanced\"]\n",
    "LIBRARIES = [(280, \"ampl2\"),\n",
    "             (280, \"frag2\")]\n",
    "NUM_READS = [2000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, 1000000]\n",
    "NUM_READS_INTS = list(range(1, len(NUM_READS) + 1))\n",
    "NUM_READS_LABELS = list(ascii_uppercase[:len(NUM_READS)])\n",
    "NUM_TRIALS = 12\n",
    "ASPECT = 0.8\n",
    "STROKE_WIDTH_MM = 0.2\n",
    "MM_TO_INCH = 5 / 127\n",
    "MM_TO_POINT = 360 / 127\n",
    "rcParams['svg.fonttype'] = \"none\"\n",
    "rcParams['font.family'] = \"Helvetica Neue\"\n",
    "rcParams['font.size'] = 6.0\n",
    "CLUST_COLORS = {1: \"#0072b2\",\n",
    "                2: \"#cc79a7\",\n",
    "                3: \"#d55e00\", \n",
    "                4: \"#e69f00\",\n",
    "                5: \"#f0e442\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d077965-0cfe-4231-aba8-b62cf6464bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic data collection and processing functions.\n",
    "\n",
    "def list_orders():\n",
    "    return list(range(1, MAX_CLUSTERS_REAL + 1))\n",
    "\n",
    "\n",
    "def list_proportions(order: int):\n",
    "    return list(zip(range(1, (len(PROP_NAMES) if order > 1 else 1) + 1),\n",
    "                    PROP_NAMES))\n",
    "\n",
    "\n",
    "def format_sample_name(order: int,\n",
    "                       props: int,\n",
    "                       library: str,\n",
    "                       n_reads: int):\n",
    "    return f\"c{order}-{props}-{library}-n{n_reads}\"\n",
    "\n",
    "\n",
    "def format_ref_name(length: int, trial: int):\n",
    "    return f\"ref-{length}\" + (f\"-{trial}\" if trial else \"\")\n",
    "\n",
    "\n",
    "def find_muts_param_file(length: int, trial: int, order: int):\n",
    "    \"\"\" Find the path to a mutation rate parameter file. \"\"\"\n",
    "    filename = f\"c{order}.muts.csv\"\n",
    "    ref = format_ref_name(length, trial)\n",
    "    return Path(\"sim\", \"params\", ref, \"full\", filename)\n",
    "\n",
    "\n",
    "def find_clusts_param_file(order: int, proportions: int):\n",
    "    \"\"\" Find the path to a cluster proportions parameter file. \"\"\"\n",
    "    filename = f\"c{order}-{proportions}.csv\"\n",
    "    return Path(\"clusts\", filename)\n",
    "\n",
    "\n",
    "def find_table_dir(length: int,\n",
    "                   trial: int,\n",
    "                   order: int,\n",
    "                   props: int,\n",
    "                   library: str,\n",
    "                   n_reads: int):\n",
    "    \"\"\" Find the directory of a table file. \"\"\"\n",
    "    sample = format_sample_name(order, props, library, n_reads)\n",
    "    ref = format_ref_name(length, trial)\n",
    "    return Path(\"sim\", \"samples\", sample, \"table\", ref, \"full\")\n",
    "\n",
    "\n",
    "def find_pos_table_file(length: int,\n",
    "                        trial: int,\n",
    "                        order: int,\n",
    "                        props: int,\n",
    "                        library: str,\n",
    "                        n_reads: int):\n",
    "    \"\"\" Find the path to a table file of positions. \"\"\"\n",
    "    return Path(find_table_dir(length, trial, order, props, library, n_reads),\n",
    "                \"clust-per-pos.csv\")\n",
    "\n",
    "\n",
    "def find_clust_table_file(length: int,\n",
    "                          trial: int,\n",
    "                          order: int,\n",
    "                          props: int,\n",
    "                          library: str,\n",
    "                          n_reads: int):\n",
    "    \"\"\" Find the path to a table file of cluster proportions. \"\"\"\n",
    "    return Path(find_table_dir(length, trial, order, props, library, n_reads),\n",
    "                \"clust-freq.csv\")\n",
    "\n",
    "\n",
    "def find_report_file(step: str,\n",
    "                     length: int,\n",
    "                     trial: int,\n",
    "                     order: int,\n",
    "                     props: int,\n",
    "                     library: str,\n",
    "                     n_reads: int):\n",
    "    \"\"\" Find the path to a report file. \"\"\"\n",
    "    sample = format_sample_name(order, props, library, n_reads)\n",
    "    ref = format_ref_name(length, trial)\n",
    "    return Path(\"sim\", \"samples\", sample, step, ref, \"full\", f\"{step}-report.json\")\n",
    "\n",
    "\n",
    "def find_mask_report_file(length: int,\n",
    "                          trial: int,\n",
    "                          order: int,\n",
    "                          props: int,\n",
    "                          library: str,\n",
    "                          n_reads: int):\n",
    "    \"\"\" Find the path to a mask report file. \"\"\"\n",
    "    return find_report_file(\"mask\", length, trial, order, props, library, n_reads)\n",
    "\n",
    "\n",
    "def find_clust_report_file(length: int,\n",
    "                           trial: int,\n",
    "                           order: int,\n",
    "                           props: int,\n",
    "                           library: str,\n",
    "                           n_reads: int):\n",
    "    \"\"\" Find the path to a cluster report file. \"\"\"\n",
    "    return find_report_file(\"cluster\", length, trial, order, props, library, n_reads)\n",
    "\n",
    "\n",
    "def get_num_reads(mask_report: Path):\n",
    "    report = MaskReport.load(mask_report)\n",
    "    return int(report.get_field(NumReadsKeptF))\n",
    "\n",
    "\n",
    "def get_num_clusters(cluster_report: Path):\n",
    "    report = ClusterReport.load(cluster_report)\n",
    "    return int(report.get_field(NumClustsF))\n",
    "\n",
    "\n",
    "def get_num_uniq_reads(cluster_report: Path):\n",
    "    report = ClusterReport.load(cluster_report)\n",
    "    return int(report.get_field(NumUniqReadKeptF))\n",
    "\n",
    "\n",
    "def load_expected_mus(csv_file: str | Path):\n",
    "    \"\"\" Load expected mutation rates from a CSV file. \"\"\"\n",
    "    data = pd.read_csv(csv_file,\n",
    "                       index_col=list(range(2)),\n",
    "                       header=list(range(3)))\n",
    "    # Cast the columns from str to int.\n",
    "    clusters = parse_header(data.columns)\n",
    "    data.columns = clusters.index\n",
    "    raw_mut_rate = (data.loc[:, \"16\"]\n",
    "                    + data.loc[:, \"32\"]\n",
    "                    + data.loc[:, \"64\"]\n",
    "                    + data.loc[:, \"128\"])\n",
    "    mus = raw_mut_rate / (raw_mut_rate + data.loc[:, \"1\"])\n",
    "    return mus.loc[:, clusters.max_order]\n",
    "\n",
    "\n",
    "def load_observed_mus(table_file: str | Path):\n",
    "    \"\"\" Load observed mutation rates from a table file. \"\"\"\n",
    "    table = load_pos_table(Path(table_file))\n",
    "    return table.fetch_ratio(rel=MUTAT_REL)[MUTAT_REL, table.header.max_order]\n",
    "\n",
    "\n",
    "def order_observed_mus(observed_mus: pd.DataFrame, assignments: np.ndarray):\n",
    "    \"\"\" Assign the observed mutation rates in the proper order. \"\"\"\n",
    "    return pd.DataFrame(observed_mus.values[:, assignments],\n",
    "                        index=observed_mus.index,\n",
    "                        columns=observed_mus.columns)\n",
    "\n",
    "\n",
    "def order_observed_pis(observed_pis: pd.DataFrame, assignments: np.ndarray):\n",
    "    \"\"\" Assign the observed proportions in the proper order. \"\"\"\n",
    "    return pd.Series(observed_pis.values[assignments],\n",
    "                     index=observed_pis.index)\n",
    "\n",
    "\n",
    "def load_expected_pis(csv_file: str | Path):\n",
    "    \"\"\" Load expected cluster proportions from a CSV file. \"\"\"\n",
    "    data = pd.read_csv(csv_file, index_col=list(range(2)))\n",
    "    clusters = parse_header(data.index)\n",
    "    return data.loc[clusters.max_order, \"Proportion\"]\n",
    "\n",
    "\n",
    "def load_observed_pis(csv_file: str | Path):\n",
    "    \"\"\" Load observed cluster proportions from a CSV file. \"\"\"\n",
    "    table = ClustFreqTableLoader(csv_file)\n",
    "    data = table.data.loc[table.header.max_order]\n",
    "    return data / data.sum()\n",
    "\n",
    "\n",
    "def calc_rms(x):\n",
    "    \"\"\" Root-mean-square. \"\"\"\n",
    "    return np.sqrt(np.nanmean(np.square(np.asarray(x))))\n",
    "\n",
    "\n",
    "def calc_barycentric_distance(x):\n",
    "    \"\"\" Calculate the distance between barycentric points. \"\"\"\n",
    "    return np.sqrt(np.sum(np.square(np.asarray(x))) / 2.)\n",
    "\n",
    "\n",
    "def calc_pearson_corr(x, y):\n",
    "    \"\"\" Pearson correlation. \"\"\"\n",
    "    return calc_pearson(np.asarray(x).reshape(-1),\n",
    "                        np.asarray(y).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bab100c-3e64-4e7a-b3f1-536dd34e8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc Data\n",
      "Clusters: 1\n",
      "Proportions: Balanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mfa/conda/envs/seismic/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/mfa/conda/envs/seismic/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/fd/r5jq1j4x5f72d0krg3f6cvdm0000gq/T/ipykernel_40250/3719378471.py:169: RuntimeWarning: Mean of empty slice\n",
      "  return np.sqrt(np.nanmean(np.square(np.asarray(x))))\n",
      "/Users/mfa/git/seismic-rna/src/seismicrna/core/mu/compare.py:104: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cov / np.sqrt(var1 * var2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 2\n",
      "Proportions: Balanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Very Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Clusters: 3\n",
      "Proportions: Balanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Very Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Clusters: 4\n",
      "Proportions: Balanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n",
      "Proportions: Very Unbalanced\n",
      "Library: 280 ampl2\n",
      "Library: 280 frag2\n"
     ]
    }
   ],
   "source": [
    "# Load all data.\n",
    "\n",
    "def calc_data(only_trial: int | None):\n",
    "    \"\"\" DataFrame of the difference between every observed and expected\n",
    "    mutation rates in every simulated dataset. \"\"\"\n",
    "    print(\"Calc Data\")\n",
    "    n_reads_data = list()\n",
    "    proportions_data = dict()\n",
    "    for order in list_orders():\n",
    "        print(\"Clusters:\", order)\n",
    "        proportions_data[order] = list()\n",
    "        for props, pname in list_proportions(order):\n",
    "            print(\"Proportions:\", pname)\n",
    "            for length, library in LIBRARIES:\n",
    "                print(\"Library:\", length, library)\n",
    "                for trial in range(NUM_TRIALS):\n",
    "                    if only_trial is not None and trial != only_trial:\n",
    "                        continue\n",
    "                    for n_reads_bin, n_reads_label, n_reads in zip(NUM_READS_INTS,\n",
    "                                                                   NUM_READS_LABELS,\n",
    "                                                                   NUM_READS,\n",
    "                                                                   strict=True):\n",
    "                        mask_report_file = find_mask_report_file(length,\n",
    "                                                                 trial,\n",
    "                                                                 order,\n",
    "                                                                 props,\n",
    "                                                                 library,\n",
    "                                                                 n_reads)\n",
    "                        clust_report_file = find_clust_report_file(length,\n",
    "                                                                   trial,\n",
    "                                                                   order,\n",
    "                                                                   props,\n",
    "                                                                   library,\n",
    "                                                                   n_reads)\n",
    "                        num_reads = get_num_reads(mask_report_file)\n",
    "                        num_uniq_reads = get_num_uniq_reads(clust_report_file)\n",
    "                        num_clusters = get_num_clusters(clust_report_file)\n",
    "                        attrs = {\"ReferenceLength\": length,\n",
    "                                 \"Trial\": trial,\n",
    "                                 \"ExpectedClusters\": order,\n",
    "                                 \"ExpectedProportions\": pname,\n",
    "                                 \"NumReadsBin\": n_reads_bin,\n",
    "                                 \"NumReadsLabel\": n_reads_label,\n",
    "                                 \"NumReads\": num_reads,\n",
    "                                 \"LogNumReads\": np.log10(num_reads),\n",
    "                                 \"NumUniqReads\": num_uniq_reads,\n",
    "                                 \"Library\": library,\n",
    "                                 \"ObservedClusters\": num_clusters}\n",
    "                        if num_clusters == order:\n",
    "                            expected_mus = load_expected_mus(find_muts_param_file(length, trial, order))\n",
    "                            observed_mus = load_observed_mus(find_pos_table_file(length,\n",
    "                                                                                 trial,\n",
    "                                                                                 order,\n",
    "                                                                                 props,\n",
    "                                                                                 library,\n",
    "                                                                                 n_reads))\n",
    "                            assignments = assign_clusterings(expected_mus.values, observed_mus.values)\n",
    "                            observed_mus_ordered = order_observed_mus(observed_mus, assignments)\n",
    "                            rmsd_mus = calc_rms(observed_mus_ordered - expected_mus)\n",
    "                            corr_mus = calc_pearson_corr(observed_mus_ordered, expected_mus)\n",
    "                            expected_pis = load_expected_pis(find_clusts_param_file(order, props))\n",
    "                            observed_pis = load_observed_pis(find_clust_table_file(length,\n",
    "                                                                                   trial,\n",
    "                                                                                   order,\n",
    "                                                                                   props,\n",
    "                                                                                   library,\n",
    "                                                                                   n_reads))\n",
    "                            observed_pis_ordered = order_observed_pis(observed_pis, assignments)\n",
    "                            norm_pis = calc_barycentric_distance(observed_pis_ordered - expected_pis)\n",
    "                            attrs[\"MutationRMSD\"] = rmsd_mus\n",
    "                            attrs[\"MutationCorr\"] = corr_mus\n",
    "                            attrs[\"ProportionNorm\"] = norm_pis\n",
    "                            proportions_data[order].append(\n",
    "                                attrs | {f\"Cluster {cluster}\": observed_pis_ordered[cluster]\n",
    "                                         for cluster in range(1, order + 1)}\n",
    "                            )\n",
    "                        n_reads_data.append(attrs)\n",
    "    n_reads_df = pd.DataFrame.from_records(n_reads_data)\n",
    "    proportions_df = {order: pd.DataFrame.from_records(data)\n",
    "                      for order, data in proportions_data.items()}\n",
    "    return n_reads_df, proportions_df\n",
    "\n",
    "n_reads_df, _ = calc_data(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72a4329-9ea0-410b-bc32-6e196a70f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data.\n",
    "\n",
    "n_reads_df.to_csv(\"raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e37471c-2234-481f-a7e0-3309fc6aa81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph details of one trial.\n",
    "\n",
    "def graph_detail(n_reads_df, proportions_df):\n",
    "    for length, library in LIBRARIES:\n",
    "        print(\"Library:\", length, library)\n",
    "        fig, axes = plt.subplots(MAX_CLUSTERS_REAL, len(PROP_NAMES) + 2)\n",
    "        for order in list_orders():\n",
    "            # Select data.\n",
    "            n_reads_df_selector = np.logical_and.reduce([n_reads_df[\"Library\"] == library,\n",
    "                                                         n_reads_df[\"ReferenceLength\"] == length,\n",
    "                                                         n_reads_df[\"ExpectedClusters\"] == order])\n",
    "            n_reads_df_selected = n_reads_df.loc[n_reads_df_selector]\n",
    "            proportions_order = proportions_df[order]\n",
    "            # Graph number of clusters observed.\n",
    "            axis = axes[order - 1, 0]\n",
    "            sns.lineplot(n_reads_df_selected,\n",
    "                         y=\"ObservedClusters\",\n",
    "                         x=\"LogNumReads\",\n",
    "                         hue=\"ExpectedProportions\",\n",
    "                         markers=True,\n",
    "                         ax=axis)\n",
    "            axis.spines.top.set_visible(False)\n",
    "            axis.spines.right.set_visible(False)\n",
    "            axis.set_xlim((3., 6.))\n",
    "            axis.set_ylim((0, 5))\n",
    "            axis.set_title(f\"Observed Number of Clusters: {order} cluster{'s' if order > 1 else ''}\")\n",
    "            # Graph correlation of mutation rates.\n",
    "            axis = axes[order - 1, 1]\n",
    "            sns.lineplot(n_reads_df_selected,\n",
    "                         y=\"MutationCorr\",\n",
    "                         x=\"LogNumReads\",\n",
    "                         hue=\"ExpectedProportions\",\n",
    "                         markers=True,\n",
    "                         ax=axis)\n",
    "            axis.spines.top.set_visible(False)\n",
    "            axis.spines.right.set_visible(False)\n",
    "            axis.set_xlim((3., 6.))\n",
    "            axis.set_ylim((0., 1.))\n",
    "            axis.set_title(f\"Mutation Rate Correlation: {order} cluster{'s' if order > 1 else ''}\")\n",
    "            for pnum, pname in list_proportions(order):\n",
    "                # Select data.\n",
    "                proportions_selector = np.logical_and.reduce([proportions_order[\"Library\"] == library,\n",
    "                                                              proportions_order[\"ReferenceLength\"] == length,\n",
    "                                                              proportions_order[\"ExpectedProportions\"] == pname])\n",
    "                proportions_selected = proportions_order[proportions_selector]\n",
    "                # Graph cluster proportions.\n",
    "                axis = axes[order - 1, pnum + 1]\n",
    "                bottom = 0.\n",
    "                for cluster in range(1, order + 1):\n",
    "                    cname = f\"Cluster {cluster}\"\n",
    "                    x = proportions_selected[\"LogNumReads\"]\n",
    "                    y = proportions_selected[cname]\n",
    "                    axis.bar(x, y, bottom=bottom, label=cname, width=0.08)\n",
    "                    bottom += y\n",
    "                axis.spines.top.set_visible(False)\n",
    "                axis.spines.right.set_visible(False)\n",
    "                axis.set_xlim((3., 6.))\n",
    "                axis.set_ylim((0., 1.))\n",
    "                axis.set_title(f\"Proportions: {order} cluster{'s' if order > 1 else ''}, {pname}\")\n",
    "        plt.show()\n",
    "\n",
    "# graph_detail(n_reads_df_trial, proportions_df_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fef379c-24b3-4ed5-8c46-c3c5197f6335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 ampl2\n",
      "280 frag2\n"
     ]
    }
   ],
   "source": [
    "# Graph how many trials detected each number of clusters.\n",
    "\n",
    "def graph_num_clusters(n_reads_df: pd.DataFrame):\n",
    "    for length, library in LIBRARIES:\n",
    "        print(length, library)\n",
    "        fig, axes = plt.subplots(MAX_CLUSTERS_REAL, len(PROP_NAMES))\n",
    "        fig.set_size_inches(75. * MM_TO_INCH, 100. * MM_TO_INCH)\n",
    "        for order in list_orders():\n",
    "            for pnum, pname in list_proportions(order):\n",
    "                axis = axes[order - 1, pnum - 1]\n",
    "                if order == 1:\n",
    "                    truth = f\"{order} Cluster\"\n",
    "                else:\n",
    "                    expected_pis = load_expected_pis(find_clusts_param_file(order, pnum))\n",
    "                    percentages = \"/\".join(str(round(p * 100.)) for p in expected_pis.values)\n",
    "                    truth = f\"{order} ({percentages})\"\n",
    "                axis.set_title(f\"Truth: {truth}\")\n",
    "                for num_reads_bin in NUM_READS_INTS:\n",
    "                    bottom = 0.\n",
    "                    # Select data.\n",
    "                    n_reads_df_selector = np.logical_and.reduce([n_reads_df[\"Library\"] == library,\n",
    "                                                                 n_reads_df[\"ReferenceLength\"] == length,\n",
    "                                                                 n_reads_df[\"ExpectedClusters\"] == order,\n",
    "                                                                 n_reads_df[\"ExpectedProportions\"] == pname,\n",
    "                                                                 n_reads_df[\"NumReadsBin\"] == num_reads_bin])\n",
    "                    n_reads_df_selected = n_reads_df.loc[n_reads_df_selector]\n",
    "                    for num_clusters in range(1, MAX_CLUSTERS_OBS + 1):\n",
    "                        height = np.count_nonzero(n_reads_df_selected[\"ObservedClusters\"] == num_clusters)\n",
    "                        axis.bar(num_reads_bin, height, bottom=bottom, width=0.8, color=CLUST_COLORS[num_clusters])\n",
    "                        bottom += height\n",
    "                axis.spines.top.set_visible(False)\n",
    "                axis.spines.right.set_visible(False)\n",
    "                axis.set_xlim((0, len(NUM_READS) + 1))\n",
    "                axis.set_ylim((0, NUM_TRIALS))\n",
    "                if pnum == 1:\n",
    "                    axis.set_yticks([0, NUM_TRIALS])\n",
    "                    axis.yaxis.set_tick_params(length=0.5 * MM_TO_POINT)\n",
    "                else:\n",
    "                    axis.spines.left.set_visible(False)\n",
    "                    axis.set_yticks([])\n",
    "                axis.set_aspect(ASPECT * len(NUM_READS) / NUM_TRIALS)\n",
    "                axis.set_xticks(NUM_READS_INTS)\n",
    "                axis.set_xticklabels(NUM_READS_LABELS)\n",
    "                axis.xaxis.set_tick_params(length=0.)\n",
    "                axis.yaxis.set_tick_params(width=STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "                axis.spines.left.set_linewidth(STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "                axis.spines.bottom.set_linewidth(STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "            for pnum in range(list_proportions(order)[-1][0] + 1, len(PROP_NAMES) + 1):\n",
    "                axis = axes[order - 1, pnum - 1]\n",
    "                axis.axis(\"off\")\n",
    "        plt.tight_layout(h_pad=0.0, w_pad=1.0)\n",
    "        plt.savefig(f\"ref-{length}_{library}_clusters.svg\")\n",
    "        plt.close()\n",
    "\n",
    "graph_num_clusters(n_reads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b894da1-f572-4eb5-9b4e-d8276842a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 ampl2 MutationCorr\n",
      "280 frag2 MutationCorr\n",
      "280 ampl2 ProportionNorm\n",
      "280 frag2 ProportionNorm\n"
     ]
    }
   ],
   "source": [
    "# Graph the accuracy for each trial.\n",
    "\n",
    "def graph_accuracies(n_reads_df: pd.DataFrame, quantity: str):\n",
    "    for length, library in LIBRARIES:\n",
    "        print(length, library, quantity)\n",
    "        fig, axes = plt.subplots(MAX_CLUSTERS_REAL, len(PROP_NAMES))\n",
    "        fig.set_size_inches(75. * MM_TO_INCH, 100. * MM_TO_INCH)\n",
    "        for order in list_orders():\n",
    "            for pnum, pname in list_proportions(order):\n",
    "                axis = axes[order - 1, pnum - 1]\n",
    "                if order == 1:\n",
    "                    truth = f\"{order} Cluster\"\n",
    "                else:\n",
    "                    expected_pis = load_expected_pis(find_clusts_param_file(order, pnum))\n",
    "                    percentages = \"/\".join(str(round(p * 100.)) for p in expected_pis.values)\n",
    "                    truth = f\"{order} ({percentages})\"\n",
    "                axis.set_title(f\"Truth: {truth}\")\n",
    "                # Select data.\n",
    "                n_reads_df_selector = np.logical_and.reduce([n_reads_df[\"Library\"] == library,\n",
    "                                                             n_reads_df[\"ReferenceLength\"] == length,\n",
    "                                                             n_reads_df[\"ExpectedClusters\"] == order,\n",
    "                                                             n_reads_df[\"ObservedClusters\"] == order,\n",
    "                                                             n_reads_df[\"ExpectedProportions\"] == pname])\n",
    "                n_reads_df_selected = n_reads_df.loc[n_reads_df_selector]\n",
    "                # Plot the data.\n",
    "                sns.stripplot(n_reads_df_selected,\n",
    "                              x=\"NumReadsBin\",\n",
    "                              y=quantity,\n",
    "                              native_scale=True,\n",
    "                              size=0.4 * MM_TO_POINT,\n",
    "                              color=CLUST_COLORS[order],\n",
    "                              ax=axis)\n",
    "                # Plot the mean of each column.\n",
    "                sns.boxplot(n_reads_df_selected,\n",
    "                            x=\"NumReadsBin\",\n",
    "                            y=quantity,\n",
    "                            native_scale=True,\n",
    "                            medianprops={'color': \"#7f7f7f\", \n",
    "                                         'ls': '-', \n",
    "                                         'lw': 0.3 * MM_TO_POINT},\n",
    "                            meanprops={\"visible\": False},\n",
    "                            whiskerprops={'visible': False},\n",
    "                            zorder=10,\n",
    "                            showfliers=False,\n",
    "                            showbox=False,\n",
    "                            showcaps=False,\n",
    "                            ax=axis)\n",
    "                axis.spines.top.set_visible(False)\n",
    "                axis.spines.right.set_visible(False)\n",
    "                axis.set_xlim((0, len(NUM_READS) + 1))\n",
    "                axis.set_ylim((0., 1.))\n",
    "                axis.set_yticks(np.linspace(0., 1., 6))\n",
    "                axis.yaxis.set_tick_params(length=0.0 * MM_TO_POINT)\n",
    "                if pnum > 1:\n",
    "                    axis.set_yticklabels([])\n",
    "                axis.set_xlabel(\"\")\n",
    "                axis.set_ylabel(\"\")\n",
    "                axis.set_aspect(ASPECT * len(NUM_READS))\n",
    "                axis.set_xticks(NUM_READS_INTS)\n",
    "                axis.set_xticklabels(NUM_READS_LABELS)\n",
    "                axis.xaxis.set_tick_params(length=0.)\n",
    "                axis.yaxis.set_tick_params(width=STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "                axis.grid(axis=\"y\", which=\"major\", visible=True, color=\"#f2f2f2\", linewidth=0.2 * MM_TO_POINT)\n",
    "                axis.spines.left.set_linewidth(STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "                axis.spines.bottom.set_linewidth(STROKE_WIDTH_MM * MM_TO_POINT)\n",
    "            for pnum in range(list_proportions(order)[-1][0] + 1, len(PROP_NAMES) + 1):\n",
    "                axis = axes[order - 1, pnum - 1]\n",
    "                axis.axis(\"off\")\n",
    "        plt.tight_layout(h_pad=0.0, w_pad=1.0)\n",
    "        plt.savefig(f\"ref-{length}_{library}_{quantity}.svg\")\n",
    "        plt.close()\n",
    "\n",
    "graph_accuracies(n_reads_df, \"MutationCorr\")\n",
    "graph_accuracies(n_reads_df, \"ProportionNorm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda0d9c-1b3d-4da7-9d7b-632f8b525b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
